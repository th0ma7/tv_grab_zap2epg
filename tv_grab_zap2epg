#!/bin/bash
# tv_grab_zap2epg gracenote.com TV schedule grabber for tvheadend
################################################################################
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
################################################################################

#
DaysPattern='^[1-9]$|^1[0-4]$'
CACodePattern='^[A-Z][0-9][A-Z][ ]?[0-9][A-Z][0-9]$'
USCodePattern='^[0-9]{5}$'
#
Quiet="false"
ZipCode=""
Offset=""
Days=""

# Function to detect system type
detect_system() {
    # Check if it's a Raspberry Pi
    if [ -f /proc/device-tree/model ] && grep -qi "raspberry" /proc/device-tree/model 2>/dev/null; then
        echo "raspberry"
    elif [ -f /proc/cpuinfo ] && grep -qi "raspberry" /proc/cpuinfo 2>/dev/null; then
        echo "raspberry"
    # Check if it's Synology
    elif [ "$(uname -a | grep -i synology)" ]; then
        echo "synology"
    else
        echo "linux"
    fi
}

# Function to backup and clean configuration file
clean_config_file() {
    local config_file="$1"
    local temp_file="${config_file}.tmp"
    local backup_file="${config_file}.backup.$(date +%Y%m%d_%H%M%S)"

    if [ -f "$config_file" ]; then
        # Create backup
        cp "$config_file" "$backup_file"
        echo "Created backup: $backup_file" >&2

        # Clean invalid entries and deprecated settings
        sed -E '
            # Remove desc01-desc20 entries
            /<setting id="desc[0-9]{2}">/d
            # Remove useragent entry (deprecated)
            /<setting id="useragent">/d
        ' "$config_file" > "$temp_file"

        # Replace original with cleaned version
        mv "$temp_file" "$config_file"
        echo "Cleaned configuration file: removed deprecated entries" >&2
    fi
}

# Manage user arguments
while [ $# -gt 0 ]; do
   case "$1" in
      -d | --description )
        printf "North America (tvlistings.gracenote.com using zap2epg)\n"
        exit 0
        ;;

      -v | --version )
        printf "3.0\n"
        exit 0
        ;;

      -c | --capabilities )
        printf "baseline\n"
        exit 0
        ;;

      -q | --quiet )
        Quiet="true"
        ;;

      -o | --output )
        shift
        XMLTV="$1"
        ;;

      -d | --days )
        shift
        Days="$1"
        ;;

      --offset )
        shift
        Offset="$1"
        ;;

      --config-file )
        shift
        ConfFile="$1"
        ;;

      --basedir )
        shift
        BaseDir="$1"
        ;;

      --zip | --postal | --code )
        shift
        # Remove " " from postal code if any
        ZipCode=$(echo ${1} | sed 's/ //g')
        ;;

      -* )
        printf "unknown option: %s\n" "$1"
        printf "Usage: %s: [--description] [--version] [--capabilities] [--basedir DIR]\n" ${0##*/}
        exit 2
        ;;
   esac
   shift
done

# Intelligent BaseDir detection if not specified via --basedir
if [ ! "${BaseDir}" ]; then
   SYSTEM_TYPE=$(detect_system)

   case "$SYSTEM_TYPE" in
       "raspberry")
           # Raspberry Pi - use Kodi path if available, otherwise default
           if [ -d "$HOME/script.module.zap2epg/epggrab" ]; then
               BaseDir="$HOME/script.module.zap2epg/epggrab"
           else
               BaseDir="$HOME/zap2epg"
           fi
           ;;
       "synology")
           # Synology NAS - enhanced logic with zap2epg subdirectory
           export PATH=/var/packages/tvheadend/target/env/bin:${PATH}
           if [ $(uname -a | sed -e 's/.* #//' -e 's/ .*//') -lt 40000 ]; then
               # DSM6
               BaseDir="/var/packages/tvheadend/target/var/epggrab/zap2epg"
           else
               # DSM7
               BaseDir="/var/packages/tvheadend/var/epggrab/zap2epg"
           fi
           ;;
       *)
           # Standard Linux - check for hts user, otherwise use $HOME/zap2epg
           if [ "$(id hts 2>/dev/null)" ]; then
               BaseDir="$HOME/zap2epg"
           else
               BaseDir="$HOME/zap2epg"
           fi
           ;;
   esac
fi

# Define directory structure based on BaseDir
CacheDir="$BaseDir/cache"
ConfDir="$BaseDir/conf"
ConfFile="$ConfDir/zap2epg.xml"
LogDir="$BaseDir/log"
LogFile="$LogDir/zap2epg.log"
XMLTV="$CacheDir/xmltv.xml"

zap2epg() {
	read -r -d '' script <<-"----EOF"
import urllib.request, urllib.error, urllib.parse
import base64
import codecs
import time
import datetime
import _strptime
import calendar
import gzip
import os
import logging
import re
import json
import sys
from os.path import dirname
import xml.etree.ElementTree as ET
from collections import OrderedDict
import hashlib
import requests
from requests.auth import HTTPDigestAuth

def mainRun(userdata):
    settingsFile = os.path.join(userdata, os.environ.get('ConfFile'))
    logging.info('Reading configuration from: %s', settingsFile)

    try:
        settings = ET.parse(settingsFile)
        root = settings.getroot()
    except Exception as e:
        logging.error('Cannot parse configuration file %s: %s', settingsFile, e)
        return None, None, None

    settingsDict = {}
    xdescOrderDict = {}
    logging.info('Running zap2epg-3.2')
    kodiVersion = root.attrib.get('version')
    logging.info('Kodi settings version: %s', kodiVersion)

    for setting in root.findall('setting'):
        settingID = setting.get('id')
        if kodiVersion == '2':
            settingStr = setting.text
        else:
            # For version 3, try the 'value' attribute first, then text
            settingStr = setting.get('value')
            if settingStr is None:
                settingStr = setting.text
            if settingStr == '':
                settingStr = None
        settingsDict[settingID] = settingStr
        logging.debug('Config setting: %s = %s (from %s)', settingID, settingStr, 'attribute' if setting.get('value') is not None else 'text')

    # Initialize variables with default values to prevent None concatenation
    stationList = None
    zipcode = None
    lineup = None
    lineupcode = None
    device = None
    days = None
    redays = None
    xdetails = False
    xdesc = False
    epicon = None
    epgenre = None
    tvhoff = False
    tvhurl = None
    tvhport = None
    usern = None
    passw = None
    chmatch = False
    tvhmatch = False
    stitle = False

    # Helper function to parse boolean values
    def parse_boolean(value):
        if value is None:
            return False
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            return value.lower() in ('true', '1', 'yes', 'on')
        return bool(value)

    for setting in settingsDict:
        if setting == 'slist':
            stationList = settingsDict[setting]
        elif setting == 'zipcode':
            if "ZipCode" in os.environ:
                zipcode = os.environ.get('ZipCode')
                logging.info('Using zipcode from environment: %s', zipcode)
            else:
                zipcode = settingsDict[setting]
                logging.info('Using zipcode from config: %s', zipcode)
        elif setting == 'lineup':
            lineup = settingsDict[setting]
        elif setting == 'lineupcode':
            lineupcode = settingsDict[setting]
        elif setting == 'device':
            device = settingsDict[setting]
        elif setting == 'days':
            if "Days" in os.environ:
                days = os.environ.get('Days')
            else:
                days = settingsDict[setting]
        elif setting == 'redays':
            redays = settingsDict[setting]
        elif setting == 'xdetails':
            xdetails = parse_boolean(settingsDict[setting])
            logging.debug('Parsed xdetails: %s -> %s', settingsDict[setting], xdetails)
        elif setting == 'xdesc':
            xdesc = parse_boolean(settingsDict[setting])
            logging.debug('Parsed xdesc: %s -> %s', settingsDict[setting], xdesc)
        elif setting == 'epicon':
            epicon = settingsDict[setting]
        elif setting == 'epgenre':
            epgenre = settingsDict[setting]
        elif setting == 'tvhoff':
            tvhoff = parse_boolean(settingsDict[setting])
            logging.debug('Parsed tvhoff: %s -> %s', settingsDict[setting], tvhoff)
        elif setting == 'tvhurl':
            tvhurl = settingsDict[setting]
        elif setting == 'tvhport':
            tvhport = settingsDict[setting]
        elif setting == 'usern':
            usern = settingsDict[setting]
        elif setting == 'passw':
            passw = settingsDict[setting]
        elif setting == 'chmatch':
            chmatch = parse_boolean(settingsDict[setting])
            logging.debug('Parsed chmatch: %s -> %s', settingsDict[setting], chmatch)
        elif setting == 'tvhmatch':
            tvhmatch = parse_boolean(settingsDict[setting])
            logging.debug('Parsed tvhmatch: %s -> %s', settingsDict[setting], tvhmatch)
        elif setting == 'stitle':
            stitle = parse_boolean(settingsDict[setting])
            logging.debug('Parsed stitle: %s -> %s', settingsDict[setting], stitle)
        elif setting.startswith('desc'):
            # Skip deprecated desc01-desc20 entries (they should be cleaned from config)
            logging.warning('Found deprecated description setting: %s (will be ignored)', setting)
        else:
            logging.debug('Unknown configuration setting: %s = %s', setting, settingsDict[setting])

    # Debug: Display all values read from configuration
    logging.info('Configuration values read:')
    logging.info('  zipcode: %s', zipcode)
    logging.info('  lineup: %s', lineup)
    logging.info('  xdetails: %s', xdetails)
    logging.info('  xdesc: %s', xdesc)

    # Validate required variables and set defaults
    if not zipcode:
        logging.error('Zipcode is required but not found in configuration')
        logging.error('Available settings in config: %s', list(settingsDict.keys()))
        # Display configuration file content for debugging
        try:
            with open(settingsFile, 'r') as f:
                config_content = f.read()
                logging.error('Configuration file content: %s', config_content)
        except Exception as e:
            logging.error('Cannot read config file: %s', e)
        return None, None, None
    if not lineupcode:
        lineupcode = 'lineupId'  # Default value
    if not device:
        device = '-'  # Default value
    if not days:
        days = '1'  # Default value

    xdescOrder = [value for (key, value) in sorted(xdescOrderDict.items())]
    if lineupcode != 'lineupId':
        chmatch = False
        tvhmatch = False
    if zipcode.isdigit():
        country = 'USA'
        logging.info('\tCountry: United States of America [%s]', country)
        logging.info('\tZIP code: %s', zipcode)
    else:
        country = 'CAN'
        logging.info('\tCountry: Canada [%s]', country)
        logging.info('\tPostal code: %s', zipcode)
    if "Offset" in os.environ:
        offset = float(os.environ.get('Offset'))
    else:
        offset = 0.0
    pythonStartTime = time.time()
    dayHours = int(days) * 8 # set back to 8 when done testing
    gridtimeStart = (int(time.mktime(time.strptime(str(datetime.datetime.now().replace(microsecond=0,second=0,minute=0)), '%Y-%m-%d %H:%M:%S'))) + offset*86400)
    cacheDir = os.path.join(userdata, os.environ.get('CacheDir'))
    schedule = {}
    tvhMatchDict = {}

    # Debug: Log description parameters
    logging.info('\tXdetails setting: %s', xdetails)
    logging.info('\tXdesc setting: %s', xdesc)

    logging.info('\tTV Guide duration: %s days', days)
    if int(offset) > 1:
        logging.info('\tTV Guide Start: %i [offset: %i days]', int(gridtimeStart), int(offset))
    elif int(offset) == 1:
        logging.info('\tTV Guide Start: %i [offset: %i day]', int(gridtimeStart), int(offset))
    else:
        logging.info('\tTV Guide Start: %i', int(gridtimeStart))
    logging.info('\tLineup: %s', lineup)
    logging.info('\tConfiguration file: %s', settingsFile)
    logging.info('\tCaching directory path: %s', cacheDir)

    # =========================================================================
    # SHARED CLASSES AND FUNCTIONS FOR OPTIMIZED DOWNLOADS
    # =========================================================================

    class OptimizedDownloader:
        """Optimized download manager with WAF protection"""

        def __init__(self, base_delay=1.0, min_delay=0.5):
            self.session = None
            self.user_agents = [
                'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15'
            ]
            self.last_request_time = 0
            self.base_delay = base_delay
            self.min_delay = min_delay
            self.current_delay = base_delay
            self.consecutive_failures = 0
            self.waf_blocks = 0
            self.total_requests = 0
            self.current_ua_index = 0

        def init_session(self):
            """Initialize optimized session with forced connection reuse"""
            if self.session:
                self.session.close()

            self.session = requests.Session()

            # Realistic headers with forced Keep-Alive
            base_headers = {
                'Accept': 'application/json, text/html, application/xhtml+xml, */*',
                'Accept-Language': 'en-US,en;q=0.9,fr;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Keep-Alive': 'timeout=60, max=100',
                'Upgrade-Insecure-Requests': '1',
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache'
            }
            self.session.headers.update(base_headers)

            # Optimized configuration for connection reuse
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry

            retry_strategy = Retry(
                total=0,
                backoff_factor=0,
                status_forcelist=[]  # Don't auto-retry
            )

            # Optimized adapter with minimal connection pool
            adapter = HTTPAdapter(
                pool_connections=1,    # Single connection pool
                pool_maxsize=1,        # Single connection in pool
                max_retries=retry_strategy,
                pool_block=True        # Block if pool full to force reuse
            )

            self.session.mount('https://', adapter)
            self.session.mount('http://', adapter)

            # Configuration urllib3 for persistence
            import urllib3
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

            # Set initial User-Agent
            self.rotate_user_agent()
            logging.info('Optimized session initialized with persistent connections')
            logging.debug('  Connection pooling: 1 connection max, keep-alive enabled')

        def rotate_user_agent(self):
            """Rotate User-Agent intelligently"""
            self.current_ua_index = (self.current_ua_index + 1) % len(self.user_agents)
            new_ua = self.user_agents[self.current_ua_index]
            self.session.headers.update({'User-Agent': new_ua})
            logging.debug('  User-Agent rotated: %s', new_ua[:50] + '...')

        def adaptive_delay(self):
            """Apply adaptive delay between requests"""
            import random

            # Calculate adaptive delay
            if self.consecutive_failures > 2:
                self.current_delay = min(self.base_delay * (1.5 ** self.consecutive_failures), 15.0)
            elif self.consecutive_failures == 0:
                self.current_delay = max(self.min_delay, self.current_delay * 0.95)

            # Add random variation
            delay = self.current_delay + random.uniform(-0.2, 0.5)
            delay = max(self.min_delay, delay)

            # Respect delay since last request
            elapsed = time.time() - self.last_request_time
            if elapsed < delay:
                sleep_time = delay - elapsed
                logging.debug('  Adaptive delay: %.2fs (failures: %d)', sleep_time, self.consecutive_failures)
                time.sleep(sleep_time)

            self.last_request_time = time.time()

        def is_waf_blocked(self, response_text):
            """Detect WAF blocking"""
            waf_indicators = [
                'Human Verification', 'captcha-container', 'AwsWafIntegration',
                '403 Forbidden', 'Access Denied', 'challenge.js'
            ]
            return any(indicator in response_text for indicator in waf_indicators)

        def handle_waf_block(self, extra_delay_range=(3, 8)):
            """Handle WAF blocking with appropriate backoff"""
            import random
            self.waf_blocks += 1
            self.consecutive_failures += 1
            extra_delay = random.uniform(*extra_delay_range)
            logging.warning('  WAF block detected, backing off %.1fs...', extra_delay)
            time.sleep(extra_delay)
            if self.total_requests % 10 == 0:  # Rotate occasionally after blocks
                self.rotate_user_agent()

        def download_with_retry_urllib(self, url, data=None, max_retries=3, timeout=None):
            """Download using urllib (like original version) with intelligent retry and WAF handling"""
            self.total_requests += 1

            # Adaptive timeouts based on history
            if timeout is None:
                if self.consecutive_failures == 0:
                    timeout = 6  # Fast if everything is OK
                elif self.consecutive_failures == 1:
                    timeout = 10  # Medium after 1 failure
                else:
                    timeout = 15  # Longer if repeated problems

            # Periodic User-Agent rotation
            if self.total_requests % 25 == 0:
                self.rotate_user_agent()

            for attempt in range(max_retries):
                self.adaptive_delay()

                current_timeout = timeout + (attempt * 2)  # Increase timeout on each retry
                current_ua = self.user_agents[self.current_ua_index]

                # Build display URL with parameters
                if data:
                    display_url = f'{url}?{data.decode("utf-8") if isinstance(data, bytes) else data}'
                else:
                    display_url = url

                logging.debug('  Attempt %d/%d: %s (timeout: %ds)',
                            attempt + 1, max_retries,
                            display_url[:100] + '...' if len(display_url) > 100 else display_url,
                            current_timeout)

                try:
                    # Use urllib exactly like the original working version
                    import urllib.request
                    URLcontent = urllib.request.Request(url, data=data, headers={'User-Agent': current_ua})
                    JSONcontent = urllib.request.urlopen(URLcontent, timeout=current_timeout).read()

                    if JSONcontent and len(JSONcontent) > 10:
                        # Check that it's valid JSON
                        try:
                            json.loads(JSONcontent)
                            self.consecutive_failures = max(0, self.consecutive_failures - 1)
                            logging.debug('  Success: %d bytes received', len(JSONcontent))
                            return JSONcontent
                        except json.JSONDecodeError:
                            logging.warning('  Invalid JSON received on attempt %d', attempt + 1)
                            self.consecutive_failures += 1
                    else:
                        logging.warning('  Empty/small response on attempt %d: %d bytes',
                                      attempt + 1, len(JSONcontent) if JSONcontent else 0)
                        self.consecutive_failures += 1

                except urllib.error.HTTPError as e:
                    if e.code == 403:
                        self.handle_waf_block()
                        continue
                    logging.warning('  HTTP Error %d on attempt %d: %s', e.code, attempt + 1, e.reason)
                    if e.code in [404, 410]:
                        break  # Don't retry for permanent errors
                    self.consecutive_failures += 1

                except urllib.error.URLError as e:
                    logging.warning('  URL Error on attempt %d: %s', attempt + 1, str(e.reason))
                    self.consecutive_failures += 1

                except Exception as e:
                    logging.warning('  Unexpected error on attempt %d: %s', attempt + 1, str(e))
                    self.consecutive_failures += 1

                # Wait before retry
                if attempt < max_retries - 1:
                    import random
                    retry_delay = random.uniform(1, 3)
                    time.sleep(retry_delay)

            # All retries failed
            logging.warning('  All %d attempts failed', max_retries)
            return None

        def download_with_retry(self, url, method='GET', data=None, max_retries=3, timeout=None):
            """Download with intelligent retry, adaptive timeouts and WAF handling (for guide)"""
            self.total_requests += 1

            # Adaptive timeouts based on history
            if timeout is None:
                if self.consecutive_failures == 0:
                    timeout = 6  # Fast if everything is OK
                elif self.consecutive_failures == 1:
                    timeout = 10  # Medium after 1 failure
                else:
                    timeout = 15  # Longer if repeated problems

            # Periodic User-Agent rotation
            if self.total_requests % 25 == 0:
                self.rotate_user_agent()

            for attempt in range(max_retries):
                self.adaptive_delay()

                current_timeout = timeout + (attempt * 2)  # Increase timeout on each retry

                # Build display URL with parameters for POST
                if method.upper() == 'POST' and data:
                    display_url = f'{url}?{data}'
                else:
                    display_url = url

                logging.debug('  Attempt %d/%d: %s (timeout: %ds)',
                            attempt + 1, max_retries,
                            display_url[:100] + '...' if len(display_url) > 100 else display_url,
                            current_timeout)

                try:
                    if method.upper() == 'POST':
                        response = self.session.post(url, data=data, timeout=current_timeout, allow_redirects=False)
                    else:
                        response = self.session.get(url, timeout=current_timeout, allow_redirects=False)

                    # Check WAF blocking
                    if response.status_code == 403:
                        self.handle_waf_block()
                        continue

                    if self.is_waf_blocked(response.text):
                        self.handle_waf_block((5, 12))  # Longer delay for CAPTCHA
                        continue

                    # Check response status
                    if response.status_code == 200:
                        self.consecutive_failures = max(0, self.consecutive_failures - 1)
                        logging.debug('  Success: %d bytes received', len(response.content))
                        return response.content
                    else:
                        logging.warning('  HTTP %d received', response.status_code)
                        if response.status_code in [404, 410]:
                            break  # Don't retry for permanent errors
                        self.consecutive_failures += 1

                except requests.exceptions.Timeout:
                    logging.warning('  Timeout (%ds) on attempt %d', current_timeout, attempt + 1)
                    self.consecutive_failures += 1

                except requests.exceptions.ConnectionError as e:
                    logging.warning('  Connection error on attempt %d: %s', attempt + 1, str(e))
                    self.consecutive_failures += 1
                    # Force reconnection on connection errors
                    self.session.close()
                    self.init_session()

                except requests.exceptions.RequestException as e:
                    logging.warning('  Request error on attempt %d: %s', attempt + 1, str(e))
                    self.consecutive_failures += 1

                # Wait before retry
                if attempt < max_retries - 1:
                    import random
                    retry_delay = random.uniform(1, 3)
                    time.sleep(retry_delay)

            # All retries failed
            logging.warning('  All %d attempts failed', max_retries)
            return None

        def close(self):
            """Clean shutdown"""
            if self.session:
                self.session.close()
                self.session = None

        def get_stats(self):
            """Get download statistics"""
            return {
                'total_requests': self.total_requests,
                'waf_blocks': self.waf_blocks,
                'consecutive_failures': self.consecutive_failures,
                'current_delay': self.current_delay
            }

    # Create shared downloader instance
    downloader = OptimizedDownloader(base_delay=0.8, min_delay=0.4)

    # Configure urllib3 logging to reduce verbosity
    import urllib3
    urllib3.disable_warnings()
    import logging as urllib_logging
    urllib_logging.getLogger("urllib3.connectionpool").setLevel(logging.WARNING)

    downloader.init_session()

    def tvhMatchGet():
        try:
            tvhUrlBase = 'http://' + tvhurl + ":" + tvhport
            channels_url = tvhUrlBase + '/api/channel/grid?all=1&limit=999999999&sort=name&filter=[{"type":"boolean","value":true,"field":"enabled"}]'
            if usern is not None and passw is not None:
                logging.info('Tvheadend access using username and password...')
                response = requests.get(channels_url, auth=HTTPDigestAuth(usern, passw), timeout=5)
            else:
                logging.info('Tvheadend anonymous access...')
                response = requests.get(channels_url, timeout=5)
            if response.status_code == 200:
                logging.info('Accessing Tvheadend channel list from: %s', tvhUrlBase)
                channels = response.json()
                for ch in channels['entries']:
                    channelName = ch['name']
                    channelNum = ch['number']
                    tvhMatchDict[channelNum] = channelName
                logging.info('%s Tvheadend channels found...', str(len(tvhMatchDict)))
            else:
                logging.warning('Tvheadend returned status code: %s', response.status_code)
        except Exception as e:
            logging.warning('Cannot connect to Tvheadend: %s', str(e))
            logging.info('Continuing without Tvheadend channel matching...')
            pass

    def deleteOldCache(gridtimeStart):
        logging.info('Checking for old cache files...')
        try:
            if os.path.exists(cacheDir):
                entries = os.listdir(cacheDir)
                for entry in entries:
                    oldfile = entry.split('.')[0]
                    if oldfile.isdigit():
                        fn = os.path.join(cacheDir, entry)
                        if (int(oldfile)) < (gridtimeStart + (int(redays) * 86400)):
                            try:
                                os.remove(fn)
                                logging.info('Deleting old cache: %s', entry)
                            except OSError as e:
                                logging.warning('Error Deleting: %s - %s.' % (e.filename, e.strerror))
        except Exception as e:
            logging.exception('Exception: deleteOldCache - %s', e.strerror)

    def deleteOldShowCache(showList):
        logging.info('Checking for old show cache files...')
        try:
            if os.path.exists(cacheDir):
                entries = os.listdir(cacheDir)
                for entry in entries:
                    oldfile = entry.split('.')[0]
                    if not oldfile.isdigit():
                        fn = os.path.join(cacheDir, entry)
                        if oldfile not in showList:
                            try:
                                os.remove(fn)
                                logging.info('Deleting old show cache: %s', entry)
                            except OSError as e:
                                logging.warning('Error Deleting: %s - %s.' % (e.filename, e.strerror))
        except Exception as e:
            logging.exception('Exception: deleteOldshowCache - %s', e.strerror)

    def convTime(t):
        return time.strftime("%Y%m%d%H%M%S",time.localtime(int(t)))

    def convHTML(data):
        if data is None:
            return ""
        data = str(data)
        data = data.replace('&','&amp;')
        data = data.replace('"','&quot;')
        data = data.replace("'",'&apos;')
        data = data.replace('<','&lt;')
        data = data.replace('>','&gt;')
        return data;

    def convTitleExcept(data):
        exception = "CTV CW HD ION ION: NHK PBS TV TVA"
        data = " ".join([word.title() if word not in exception else word for word in data.split(" ")])
        return data;

    def savepage(fn, data):
        if not os.path.exists(cacheDir):
            os.mkdir(cacheDir)
        fileDir = os.path.join(cacheDir, fn)
        with gzip.open(fileDir,"wb+") as f:
            f.write(data)
            f.close()

    def genreSort(EPfilter, EPgenre):
        genreList = []
        if epgenre == '2':
            # for f in EPfilter:
            #     fClean = re.sub('filter-','',f)
            #     genreList.append(fClean)
            for g in EPgenre:
                if g != "Comedy":
                    genreList.append(g)
            if 'Movie' in genreList or 'movie' in genreList or 'Movies' in genreList:
                genreList.insert(0, "Movie / Drama")
            if 'News' in genreList:
                genreList.insert(0, "News / Current affairs")
            if 'Game show' in genreList:
                genreList.insert(0, "Game show / Quiz / Contest")
            if 'Law' in genreList:
                genreList.insert(0, "Show / Game show")
            if 'Art' in genreList or 'Culture' in genreList:
                genreList.insert(0, "Arts / Culture (without music)")
            if 'Entertainment' in genreList:
                genreList.insert(0, "Popular culture / Traditional Arts")
            if 'Politics' in genreList or 'Social' in genreList or 'Public affairs' in genreList:
                genreList.insert(0, "Social / Political issues / Economics")
            if 'Education' in genreList or 'Science' in genreList:
                genreList.insert(0, "Education / Science / Factual topics")
            if 'How-to' in genreList:
                genreList.insert(0, "Leisure hobbies")
            if 'Travel' in genreList:
                genreList.insert(0, "Tourism / Travel")
            if 'Sitcom' in genreList:
                genreList.insert(0, "Variety show")
            if 'Talk' in genreList:
                genreList.insert(0, "Talk show")
            if 'Children' in genreList:
                genreList.insert(0, "Children's / Youth programs")
            if 'Animated' in genreList:
                genreList.insert(0, "Cartoons / Puppets")
            if 'Music' in genreList:
                genreList.insert(0, "Music / Ballet / Dance")
        if epgenre == '1':
            # for f in EPfilter:
            #     fClean = re.sub('filter-','',f)
            #     genreList.append(fClean)
            for g in EPgenre:
                genreList.append(g)
            if 'Movie' in genreList or 'movie' in genreList or 'Movies' in genreList:
                genreList = ["Movie / Drama"]
            elif 'News' in genreList:
                genreList = ["News / Current affairs"]
            elif 'News magazine' in genreList:
                genreList = ["News magazine"]
            elif 'Public affairs' in genreList:
                genreList = ["News / Current affairs"]
            elif 'Interview' in genreList:
                genreList = ["Discussion / Interview / Debate"]
            elif 'Game show' in genreList:
                genreList = ["Game show / Quiz / Contest"]
            elif 'Talk' in genreList:
                genreList = ["Talk show"]
            elif 'Sports' in genreList:
                genreList = ["Sports"]
            elif 'Sitcom' in genreList:
                genreList = ["Variety show"]
            elif 'Children' in genreList:
                genreList = ["Children's / Youth programs"]
            else:
                genreList = ["Variety show"]
        if epgenre == '3':
            # for f in EPfilter:
            #     fClean = re.sub('filter-','',f)
            #     genreList.append(fClean)
            for g in EPgenre:
                genreList.append(g)
        if 'Movie' in genreList:
            genreList.remove('Movie')
            genreList.insert(0, 'Movie')
        return genreList

    def printHeader(fh, enc):
        logging.info('Creating xmltv.xml file...')
        fh.write("<?xml version=\"1.0\" encoding=\""+ enc + "\"?>\n")
        fh.write("<!DOCTYPE tv SYSTEM \"xmltv.dtd\">\n\n")
        fh.write("<tv source-info-url=\"http://tvschedule.gracenote.com/\" source-info-name=\"gracenote.com\">\n")

    def printFooter(fh):
        fh.write("</tv>\n")

    def printStations(fh):
        global stationCount
        stationCount = 0
        try:
            logging.info('Writing Stations to xmltv.xml file...')
            try:
                scheduleSort = OrderedDict(sorted(iter(schedule.items()), key=lambda x: int(x[1]['chnum'])))
            except:
                scheduleSort = OrderedDict(sorted(iter(schedule.items()), key=lambda x: x[1]['chfcc']))
            for station in scheduleSort:
                fh.write('\t<channel id=\"' + station + '.zap2epg\">\n')
                if 'chtvh' in scheduleSort[station] and scheduleSort[station]['chtvh'] is not None:
                    xchtvh = convHTML(scheduleSort[station]['chtvh'])
                    fh.write('\t\t<display-name>' + xchtvh + '</display-name>\n')
                if 'chnum' in scheduleSort[station] and 'chfcc' in scheduleSort[station]:
                    xchnum = scheduleSort[station]['chnum']
                    xchfcc = scheduleSort[station]['chfcc']
                    xchnam = scheduleSort[station]['chnam']
                    fh.write('\t\t<display-name>' + xchnum + ' ' + convHTML(xchfcc) + '</display-name>\n')
                    if xchnam != "INDEPENDENT":
                        fh.write('\t\t<display-name>' + convHTML(xchnam) + '</display-name>\n')
                    fh.write('\t\t<display-name>' + convHTML(xchfcc) + '</display-name>\n')
                    fh.write('\t\t<display-name>' + xchnum + '</display-name>\n')
                elif 'chfcc' in scheduleSort[station]:
                    xchnum = scheduleSort[station]['chfcc']
                    fh.write('\t\t<display-name>' + convHTML(xchfcc) + '</display-name>\n')
                elif 'chnum' in scheduleSort[station]:
                    xchnum = scheduleSort[station]['chnum']
                    fh.write('\t\t<display-name>' + xchnum + '</display-name>\n')
                if 'chicon' in scheduleSort[station]:
                    fh.write("\t\t<icon src=\"http:" + scheduleSort[station]['chicon'] + "\" />\n")
                fh.write("\t</channel>\n")
                stationCount += 1
        except Exception as e:
            logging.exception('Exception: printStations')

    def printEpisodes(fh):
        global episodeCount
        episodeCount = 0
        desc_count = 0
        xdesc_count = 0
        try:
            logging.info('Writing Episodes to xmltv.xml file...')
            if xdesc is True:
                logging.info('Extended descriptions enabled (xdesc=true)')
            else:
                logging.info('Using basic descriptions only (xdesc=false)')

            for station in schedule:
                lang = 'en'
                sdict = schedule[station]
                for episode in sdict:
                    if not episode.startswith("ch"):
                        try:
                            edict = sdict[episode]
                            if 'epstart' in edict:
                                startTime = convTime(edict['epstart'])
                                is_dst = time.daylight and time.localtime().tm_isdst > 0
                                TZoffset = "%.2d%.2d" %(- (time.altzone if is_dst else time.timezone)/3600, 0)
                                stopTime = convTime(edict['epend'])
                                fh.write('\t<programme start=\"' + startTime + ' ' + TZoffset + '\" stop=\"' + stopTime + ' ' + TZoffset + '\" channel=\"' + station + '.zap2epg' + '\">\n')
                                dd_progid = edict['epid']
                                fh.write('\t\t<episode-num system=\"dd_progid\">' + dd_progid[:-4] + '.' + dd_progid[-4:] + '</episode-num>\n')
                                if edict['epshow'] is not None:
                                    fh.write('\t\t<title lang=\"' + lang + '\">' + convHTML(edict['epshow']) + '</title>\n')
                                if edict['eptitle'] is not None:
                                    showTitle = convHTML(edict['eptitle'])
                                    if stitle:
                                        safeTitle = re.sub('[\\/*?:|]', "_", showTitle)
                                        fh.write('\t\t<sub-title lang=\"' + lang + '\">' + safeTitle + '</sub-title>\n')
                                    else:
                                        fh.write('\t\t<sub-title lang=\"' + lang + '\">' + showTitle + '</sub-title>\n')

                                # MAJOR FIX: Logic for descriptions with proper fallback
                                description_written = False

                                # Try extended descriptions first if enabled
                                if xdesc is True:
                                    try:
                                        xdescSort = addXDetails(edict)
                                        if xdescSort is not None and xdescSort.strip():
                                            fh.write('\t\t<desc lang=\"' + lang + '\">' + convHTML(xdescSort) + '</desc>\n')
                                            xdesc_count += 1
                                            description_written = True
                                    except Exception as e:
                                        logging.warning('Error generating extended description for episode %s: %s', episode, str(e))

                                # Fallback to basic description if no extended description was written
                                if not description_written:
                                    if edict.get('epdesc') is not None and str(edict['epdesc']).strip():
                                        fh.write('\t\t<desc lang=\"' + lang + '\">' + convHTML(edict['epdesc']) + '</desc>\n')
                                        desc_count += 1
                                        description_written = True

                                # Debug: count episodes without description
                                if not description_written:
                                    logging.warning('No description available for: %s - %s',
                                                  edict.get('epshow', 'Unknown'),
                                                  edict.get('eptitle', ''))

                                if edict['eplength'] is not None:
                                    fh.write('\t\t<length units="minutes">' + edict['eplength'] + '</length>\n')
                                if edict['epsn'] is not None and edict['epen'] is not None:
                                    fh.write("\t\t<episode-num system=\"onscreen\">" + 'S' + edict['epsn'].zfill(2) + 'E' + edict['epen'].zfill(2) + "</episode-num>\n")
                                    fh.write("\t\t<episode-num system=\"xmltv_ns\">" + str(int(edict['epsn'])-1) +  "." + str(int(edict['epen'])-1) + ".</episode-num>\n")
                                if edict['epyear'] is not None:
                                    fh.write('\t\t<date>' + edict['epyear'] + '</date>\n')
                                if not episode.startswith("MV"):
                                    if epicon == '1':
                                        if edict['epimage'] is not None and edict['epimage'] != '':
                                            fh.write('\t\t<icon src="https://zap2it.tmsimg.com/assets/' + edict['epimage'] + '.jpg" />\n')
                                        else:
                                            if edict['epthumb'] is not None and edict['epthumb'] != '':
                                                fh.write('\t\t<icon src="https://zap2it.tmsimg.com/assets/' + edict['epthumb'] + '.jpg" />\n')
                                    if epicon == '2':
                                        if edict['epthumb'] is not None and edict['epthumb'] != '':
                                            fh.write('\t\t<icon src="https://zap2it.tmsimg.com/assets/' + edict['epthumb'] + '.jpg" />\n')
                                if episode.startswith("MV"):
                                    if edict['epthumb'] is not None and edict['epthumb'] != '':
                                        fh.write('\t\t<icon src="https://zap2it.tmsimg.com/assets/' + edict['epthumb'] + '.jpg" />\n')
                                if not any(i in ['New', 'Live'] for i in edict['epflag']):
                                    fh.write("\t\t<previously-shown ")
                                    if edict['epoad'] is not None and int(edict['epoad']) > 0:
                                        fh.write("start=\"" + convTime(edict['epoad']) + " " + TZoffset + "\"")
                                    fh.write(" />\n")
                                if edict['eptags'] is not None:
                                    if 'CC' in edict['eptags']:
                                        fh.write('\t\t<subtitles type="teletext" />\n')
                                if edict['epflag'] is not None:
                                    if 'Finale' in edict['epflag']:
                                        fh.write("\t\t<last-chance />\n")
                                    if 'Live' in edict['epflag']:
                                        fh.write("\t\t<live />\n")
                                    if 'New' in edict['epflag']:
                                        fh.write("\t\t<new />\n")
                                    if 'Premiere' in edict['epflag']:
                                        fh.write("\t\t<premiere />\n")
                                if edict['eprating'] is not None:
                                    fh.write('\t\t<rating>\n\t\t\t<value>' + edict['eprating'] + '</value>\n\t\t</rating>\n')
                                if edict['epstar'] is not None:
                                    fh.write('\t\t<star-rating>\n\t\t\t<value>' + edict['epstar'] + '/4</value>\n\t\t</star-rating>\n')
                                if edict['epcredits'] is not None:
                                    fh.write("\t\t<credits>\n")
                                    for c in edict['epcredits']:
                                        if c['assetId'] is not None and c['assetId'] != '':
                                            crole=c['role']
                                            fh.write('\t\t\t<' + c['role'].lower() + ' role="' + convHTML(c['characterName']) + '" src="https://zap2it.tmsimg.com/assets/' + c['assetId'] + '.jpg">' + convHTML(c['name']) + '</' + c['role'].lower() + '>\n')
                                        else:
                                            fh.write('\t\t\t<' + c['role'].lower() + ' role="' + convHTML(c['characterName']) + '">' + convHTML(c['name']) + '</' + c['role'].lower() + '>\n')
                                    fh.write("\t\t</credits>\n")
                                if epgenre != '0':
                                    if edict['epfilter'] is not None and edict['epgenres'] is not None:
                                        genreNewList = genreSort(edict['epfilter'], edict['epgenres'])
                                    elif edict['epfilter'] is not None:
                                        genreNewList = edict['epfilter']
                                    if genreNewList != "":
                                        for genre in genreNewList:
                                            fh.write("\t\t<category lang=\"" + lang + "\">" + convHTML(genre).replace('filter-','') + "</category>\n")
                                fh.write("\t</programme>\n")
                                episodeCount += 1
                        except Exception as e:
                            logging.exception('Error processing episode %s:', episode)

            # Log description statistics
            logging.info('Description statistics: Episodes=%d, Basic_desc=%d, Extended_desc=%d',
                        episodeCount, desc_count, xdesc_count)
        except Exception as e:
            logging.exception('Exception: printEpisodes')

    def xmltv():
        try:
            enc = 'utf-8'
            outFile = os.path.join(userdata, os.environ.get('XMLTV'))
            fh = codecs.open(outFile, 'w+b', encoding=enc)
            printHeader(fh, enc)
            printStations(fh)
            printEpisodes(fh)
            printFooter(fh)
            fh.close()
        except Exception as e:
            logging.exception('Exception: xmltv')

    def parseStations(content):
        try:
            ch_guide = json.loads(content)
            for station in ch_guide['channels']:
                skey = station.get('channelId')
                if stationList is not None:
                    if skey in stationList:
                        schedule[skey] = {}
                        chSign = station.get('callSign')
                        chName = station.get('affiliateName')
                        schedule[skey]['chfcc'] = chSign
                        schedule[skey]['chnam'] = chName
                        schedule[skey]['chicon'] = station.get('thumbnail').split('?')[0]
                        chnumStart = station.get('channelNo')
                        if '.' not in chnumStart and chmatch and chSign is not None:
                            chsub = re.search(r'(\d+)$', chSign)
                            if chsub is not None:
                                chnumUpdate = chnumStart + '.' + chsub.group(0)
                            else:
                                chnumUpdate = chnumStart + '.1'
                        else:
                            chnumUpdate = chnumStart
                        schedule[skey]['chnum'] = chnumUpdate
                        if tvhmatch and '.' in chnumUpdate:
                            if chnumUpdate in tvhMatchDict:
                                schedule[skey]['chtvh'] = tvhMatchDict[chnumUpdate]
                            else:
                                schedule[skey]['chtvh'] = None
                else:
                    schedule[skey] = {}
                    chSign = station.get('callSign')
                    chName = station.get('affiliateName')
                    schedule[skey]['chfcc'] = chSign
                    schedule[skey]['chnam'] = chName
                    schedule[skey]['chicon'] = station.get('thumbnail').split('?')[0]
                    chnumStart = station.get('channelNo')
                    if '.' not in chnumStart and chmatch and chSign is not None:
                        chsub = re.search(r'(\d+)$', chSign)
                        if chsub is not None:
                            chnumUpdate = chnumStart + '.' + chsub.group(0)
                        else:
                            chnumUpdate = chnumStart + '.1'
                    else:
                        chnumUpdate = chnumStart
                    schedule[skey]['chnum'] = chnumUpdate
                    if tvhmatch and '.' in chnumUpdate:
                        if chnumUpdate in tvhMatchDict:
                            schedule[skey]['chtvh'] = tvhMatchDict[chnumUpdate]
                        else:
                            schedule[skey]['chtvh'] = None
        except Exception as e:
            logging.exception('Exception: parseStations')

    def parseEpisodes(content):
        CheckTBA = "Safe"
        try:
            ch_guide = json.loads(content)
            for station in ch_guide['channels']:
                skey = station.get('channelId')
                if stationList is not None:
                    if skey in stationList:
                        episodes = station.get('events')
                        for episode in episodes:
                            epkey = str(calendar.timegm(time.strptime(episode.get('startTime'), '%Y-%m-%dT%H:%M:%SZ')))
                            schedule[skey][epkey] = {}

                            # CRITICAL FIX: improved description retrieval
                            program = episode.get('program', {})
                            shortDesc = program.get('shortDesc') or ''
                            longDesc = program.get('longDesc') or ''

                            # Handle None values properly
                            if shortDesc is None:
                                shortDesc = ''
                            if longDesc is None:
                                longDesc = ''

                            # Debug: log if no description found
                            if not shortDesc and not longDesc:
                                logging.debug('No description found for: %s - %s',
                                            program.get('title', 'Unknown'),
                                            program.get('episodeTitle', ''))

                            schedule[skey][epkey]['epid'] = episode['program'].get('tmsId')
                            schedule[skey][epkey]['epstart'] = str(calendar.timegm(time.strptime(episode.get('startTime'), '%Y-%m-%dT%H:%M:%SZ')))
                            schedule[skey][epkey]['epend'] = str(calendar.timegm(time.strptime(episode.get('endTime'), '%Y-%m-%dT%H:%M:%SZ')))
                            schedule[skey][epkey]['eplength'] = episode.get('duration')
                            schedule[skey][epkey]['epshow'] = episode['program'].get('title')
                            schedule[skey][epkey]['eptitle'] = episode['program'].get('episodeTitle')
                            schedule[skey][epkey]['epdesc'] = longDesc if longDesc else shortDesc  # Fix: priority to longDesc
                            schedule[skey][epkey]['epyear'] = episode['program'].get('releaseYear')
                            schedule[skey][epkey]['eprating'] = episode.get('rating')
                            schedule[skey][epkey]['epflag'] = episode.get('flag')
                            schedule[skey][epkey]['eptags'] = episode.get('tags')
                            schedule[skey][epkey]['epsn'] = episode['program'].get('season')
                            schedule[skey][epkey]['epen'] = episode['program'].get('episode')
                            schedule[skey][epkey]['epthumb'] = episode.get('thumbnail')
                            schedule[skey][epkey]['epoad'] = None
                            schedule[skey][epkey]['epstar'] = None
                            schedule[skey][epkey]['epfilter'] = episode.get('filter')
                            schedule[skey][epkey]['epgenres'] = None
                            schedule[skey][epkey]['epcredits'] = None
                            schedule[skey][epkey]['epxdesc'] = None
                            schedule[skey][epkey]['epseries'] = episode['program'].get('seriesId')  # CRITICAL FIX: seriesId is in program
                            schedule[skey][epkey]['epimage'] = None
                            schedule[skey][epkey]['epfan'] = None
                            if "TBA" in schedule[skey][epkey]['epshow']:
                                CheckTBA = "Unsafe"
                            elif schedule[skey][epkey]['eptitle']:
                                if "TBA" in schedule[skey][epkey]['eptitle']:
                                    CheckTBA = "Unsafe"
                else:
                    episodes = station.get('events')
                    for episode in episodes:
                        epkey = str(calendar.timegm(time.strptime(episode.get('startTime'), '%Y-%m-%dT%H:%M:%SZ')))
                        schedule[skey][epkey] = {}

                        # CRITICAL FIX: improved description retrieval
                        program = episode.get('program', {})
                        shortDesc = program.get('shortDesc') or ''
                        longDesc = program.get('longDesc') or ''

                        # Handle None values properly
                        if shortDesc is None:
                            shortDesc = ''
                        if longDesc is None:
                            longDesc = ''

                        schedule[skey][epkey]['epid'] = episode['program'].get('tmsId')
                        schedule[skey][epkey]['epstart'] = str(calendar.timegm(time.strptime(episode.get('startTime'), '%Y-%m-%dT%H:%M:%SZ')))
                        schedule[skey][epkey]['epend'] = str(calendar.timegm(time.strptime(episode.get('endTime'), '%Y-%m-%dT%H:%M:%SZ')))
                        schedule[skey][epkey]['eplength'] = episode.get('duration')
                        schedule[skey][epkey]['epshow'] = episode['program'].get('title')
                        schedule[skey][epkey]['eptitle'] = episode['program'].get('episodeTitle')
                        schedule[skey][epkey]['epdesc'] = longDesc if longDesc else shortDesc  # Fix: priority to longDesc
                        schedule[skey][epkey]['epyear'] = episode['program'].get('releaseYear')
                        schedule[skey][epkey]['eprating'] = episode.get('rating')
                        schedule[skey][epkey]['epflag'] = episode.get('flag')
                        schedule[skey][epkey]['eptags'] = episode.get('tags')
                        schedule[skey][epkey]['epsn'] = episode['program'].get('season')
                        schedule[skey][epkey]['epen'] = episode['program'].get('episode')
                        schedule[skey][epkey]['epthumb'] = episode.get('thumbnail')
                        schedule[skey][epkey]['epoad'] = None
                        schedule[skey][epkey]['epstar'] = None
                        schedule[skey][epkey]['epfilter'] = episode.get('filter')
                        schedule[skey][epkey]['epgenres'] = None
                        schedule[skey][epkey]['epcredits'] = None
                        schedule[skey][epkey]['epxdesc'] = None
                        schedule[skey][epkey]['epseries'] = episode['program'].get('seriesId')  # CRITICAL FIX: seriesId is in program
                        schedule[skey][epkey]['epimage'] = None
                        schedule[skey][epkey]['epfan'] = None
                        if "TBA" in schedule[skey][epkey]['epshow']:
                            CheckTBA = "Unsafe"
                        elif schedule[skey][epkey]['eptitle']:
                            if "TBA" in schedule[skey][epkey]['eptitle']:
                                CheckTBA = "Unsafe"
        except Exception as e:
            logging.exception('Exception: parseEpisodes')
        return CheckTBA

    def genShowList():
        showList = []
        for station in schedule:
            sdict = schedule[station]
            for episode in sdict:
                if not episode.startswith("ch"):
                    edict = sdict[episode]
                    if edict.get('epseries'):
                        showList.append(edict['epseries'])
        return showList

    def parseXdetails():
        showList = []
        failList = []
        download_count = 0
        success_count = 0

        logging.info('Starting extended details download using optimized session')

        try:
            for station in schedule:
                sdict = schedule[station]
                for episode in sdict:
                    if not episode.startswith("ch"):
                        edict = sdict[episode]
                        EPseries = edict.get('epseries')

                        # Check that EPseries is not None or empty
                        if not EPseries or EPseries in failList:
                            continue

                        showList.append(EPseries)
                        filename = EPseries + '.json'
                        fileDir = os.path.join(cacheDir, filename)

                        try:
                            if not os.path.exists(fileDir):
                                download_count += 1

                                url = 'https://tvlistings.gracenote.com/api/program/overviewDetails'
                                data = 'programSeriesID=' + EPseries

                                # Display complete URL with parameters for debug (as before)
                                full_url_display = f'{url}?{data}'
                                logging.info('Downloading details data for: %s', EPseries)
                                logging.debug('  URL: %s', full_url_display)

                                # FIX: Use exactly the same method as the working original version
                                # Encode data like in the original version
                                data_encode = data.encode('utf-8')

                                # Use optimized downloader with correct parameters
                                content = downloader.download_with_retry_urllib(url, data=data_encode, timeout=6)

                                if content:
                                    try:
                                        # Check that it's valid JSON
                                        json.loads(content)
                                        # Save file
                                        with open(fileDir, "wb") as f:
                                            f.write(content)
                                        logging.info('  Successfully downloaded: %s (%d bytes)', filename, len(content))
                                        success_count += 1
                                    except json.JSONDecodeError:
                                        logging.warning('  Invalid JSON received for: %s', EPseries)
                                        failList.append(EPseries)
                                    except Exception as e:
                                        logging.warning('  Error saving details %s: %s', filename, str(e))
                                        failList.append(EPseries)
                                else:
                                    logging.warning('  Failed to download details for: %s', EPseries)
                                    failList.append(EPseries)

                            # Parse downloaded or cached file
                            if os.path.exists(fileDir):
                                fileSize = os.path.getsize(fileDir)
                                if fileSize > 0:
                                    try:
                                        with open(fileDir, 'rb') as f:
                                            EPdetails = json.loads(f.read())

                                        logging.debug('Parsing %s (%d bytes)', filename, fileSize)

                                        # Process details (existing code)
                                        edict['epimage'] = EPdetails.get('seriesImage')
                                        edict['epfan'] = EPdetails.get('backgroundImage')
                                        EPgenres = EPdetails.get('seriesGenres')

                                        if filename.startswith("MV"):
                                            overview_tab = EPdetails.get('overviewTab', {})
                                            if isinstance(overview_tab, dict):
                                                edict['epcredits'] = overview_tab.get('cast')
                                            EPgenres = 'Movie|' + EPgenres if EPgenres else 'Movie'

                                        if EPgenres:
                                            edict['epgenres'] = EPgenres.split('|')

                                        EPlist = EPdetails.get('upcomingEpisodeTab', [])
                                        if not isinstance(EPlist, list):
                                            EPlist = []

                                        EPid = edict.get('epid', '')
                                        for airing in EPlist:
                                            if not isinstance(airing, dict):
                                                continue

                                            if EPid.lower() == airing.get('tmsID', '').lower():
                                                if not episode.startswith("MV"):
                                                    try:
                                                        origDate = airing.get('originalAirDate')
                                                        if origDate and origDate != '':
                                                            EPoad = re.sub('Z', ':00Z', origDate)
                                                            edict['epoad'] = str(calendar.timegm(time.strptime(EPoad, '%Y-%m-%dT%H:%M:%SZ')))
                                                    except Exception:
                                                        pass # Ignore date parsing errors

                                                    try:
                                                        TBAcheck = airing.get('episodeTitle', '')
                                                        if TBAcheck and "TBA" in TBAcheck:
                                                            try:
                                                                os.remove(fileDir)
                                                                logging.info('  Deleted %s (TBA listing)', filename)
                                                                if EPseries in showList:
                                                                    showList.remove(EPseries)
                                                            except OSError:
                                                                pass
                                                    except Exception:
                                                        pass

                                    except json.JSONDecodeError:
                                        logging.warning('  Invalid JSON in cached file: %s - deleting', filename)
                                        try:
                                            os.remove(fileDir)
                                        except:
                                            pass
                                    except Exception as e:
                                        logging.warning('  Error parsing cached file %s: %s', filename, str(e))

                                else:
                                    logging.warning('  Empty cached file: %s - deleting', filename)
                                    try:
                                        os.remove(fileDir)
                                    except:
                                        pass

                        except Exception as e:
                            logging.warning('  Critical error processing %s: %s', episode, str(e))

            # Final statistics
            stats = downloader.get_stats()
            logging.info('Extended details download completed:')
            logging.info('  Downloads attempted: %d', download_count)
            logging.info('  Successful downloads: %d', success_count)
            logging.info('  Failed downloads: %d', len(failList))
            logging.info('  WAF blocks during details: %d', stats['waf_blocks'])
            logging.info('  Success rate: %.1f%%', (success_count/download_count*100) if download_count > 0 else 0)

            if failList:
                logging.info('  Failed series (first 10): %s', ', '.join(failList[:10]))

        except Exception as e:
            logging.error('Critical error in parseXdetails: %s', str(e))

    def addXDetails(edict):
        try:
            ratings = ""
            date = ""
            myear = ""
            new = ""
            live = ""
            hd = ""
            cc = ""
            cast = ""
            season = ""
            epis = ""
            episqts = ""
            prog = ""
            plot= ""
            descsort = ""
            bullet = "\u2022 "
            hyphen = "\u2013 "
            newLine = "\n"
            space = " "
            colon = "\u003A "
            vbar = "\u007C "
            slash = "\u2215 "
            comma = "\u002C "

            def getSortName(opt):
                return {
                    1: bullet,
                    2: newLine,
                    3: hyphen,
                    4: space,
                    5: colon,
                    6: vbar,
                    7: slash,
                    8: comma,
                    9: plot,
                    10: new,
                    11: hd,
                    12: cc,
                    13: season,
                    14: ratings,
                    15: date,
                    16: prog,
                    17: epis,
                    18: episqts,
                    19: cast,
                    20: myear,
                }.get(opt, None)

            def cleanSortList(optList):
                cleanList=[]
                optLen = len(optList)
                for opt in optList:
                    if opt is not None and str(opt).isdigit():
                        thisOption = getSortName(int(opt))
                        if thisOption is not None:
                            cleanList.append(int(opt))
                for item in reversed(cleanList):
                    if cleanList and cleanList[-1] <= 8:
                        del cleanList[-1]
                return cleanList

            def makeDescsortList(optList):
                sortOrderList =[]
                lastOption = 1
                cleanedList = cleanSortList(optList)
                for opt in cleanedList:
                    thisOption = getSortName(int(opt))
                    if int(opt) <= 8 and lastOption <= 8:
                        if int(opt) == 2 and len(sortOrderList) > 1:
                            del sortOrderList[-1]
                            sortOrderList.append(thisOption)
                        lastOption = int(opt)
                    elif thisOption and lastOption:
                        sortOrderList.append(thisOption)
                        lastOption = int(opt)
                    elif thisOption:
                        lastOption = int(opt)
                return sortOrderList

            if edict.get('epoad') is not None and int(edict['epoad']) > 0:
                is_dst = time.daylight and time.localtime().tm_isdst > 0
                TZoffset = (time.altzone if is_dst else time.timezone)
                origDate = int(edict['epoad']) + TZoffset
                finalDate = datetime.datetime.fromtimestamp(origDate).strftime('%Y-%m-%d')
                finalDate = re.sub('%', ',', finalDate)
                date = "Premiere: " + finalDate + space
            if edict.get('epyear') is not None:
                myear = str(edict['epyear']) + space
            if edict.get('eprating') is not None:
                ratings = str(edict['eprating']) + space
            if edict.get('eptags') and edict['eptags'] != []:
                tagsList = edict['eptags']
                cc = ' | '.join(tagsList).upper() + space
            #if edict['ephd'] is not None:
                #hd = edict['ephd'] + space
            if edict.get('epsn') is not None and edict.get('epen') is not None:
                s = re.sub('S', '', str(edict['epsn']))
                sf = "S" + str(int(s))
                e = re.sub('E', '', str(edict['epen']))
                ef = "E" + str(int(e))
                season = sf + " - " + ef + space
            if edict.get('epshow') is not None:
                prog = str(edict['epshow']) + space
            if edict.get('eptitle') is not None:
                epis = str(edict['eptitle']) + space
                episqts = '\"' + str(edict['eptitle']) + '\"' + space
            if edict.get('epdesc') is not None:
                plot = str(edict['epdesc']) + space

            # todo - handle star ratings

            # Only create extended description if we have xdescOrder configuration
            if xdescOrder and len(xdescOrder) > 0:
                descsort = "".join(makeDescsortList(xdescOrder))
                # Return extended description only if it's different from basic description
                if descsort.strip() and descsort.strip() != plot.strip():
                    return descsort

            # Return None to indicate no extended description available (fallback to basic)
            return None
        except Exception as e:
            logging.exception('Exception: addXdetails to description')
            # In case of error, return None to trigger fallback to basic description
            return None

    try:
        if not os.path.exists(cacheDir):
            os.mkdir(cacheDir)
        count = 0
        gridtime = gridtimeStart
        if stationList is None:
            logging.info('No channel list found - adding all stations!')
        if tvhoff and tvhmatch:
            tvhMatchGet()
        deleteOldCache(gridtimeStart)

        # OPTIMIZED MAIN GUIDE DOWNLOAD
        logging.info('Starting main guide download with optimized session')
        guide_download_start = time.time()

        while count < dayHours:
            filename = str(int(gridtime)) + '.json.gz'
            fileDir = os.path.join(cacheDir, filename)

            if not os.path.exists(fileDir):
                # Build download URL
                url = ('http://tvlistings.gracenote.com/api/grid?aid=orbebb&TMSID=&AffiliateID=lat&FromPage=TV%20Grid&lineupId=&timespan=3&headendId=' +
                       str(lineupcode) + '&country=' + str(country) + '&device=' + str(device) + '&postalCode=' +
                       str(zipcode) + '&time=' + str(int(gridtime)) + '&isOverride=true&pref=-&userId=-')

                logging.info('Downloading guide data for: %i (%s)', int(gridtime), filename)
                logging.debug('  URL: %s', url)

                # Use optimized downloader
                content = downloader.download_with_retry(url, method='GET', timeout=8)  # Shorter timeout for guide

                if content:
                    try:
                        # Check that it's valid JSON
                        json.loads(content)
                        # Save in gzip format
                        savepage(filename, content)
                        logging.info('  Successfully downloaded guide: %s (%d bytes)', filename, len(content))
                    except json.JSONDecodeError:
                        logging.warning('  Invalid JSON received for guide time: %i', int(gridtime))
                    except Exception as e:
                        logging.warning('  Error saving guide %s: %s', filename, str(e))
                else:
                    logging.warning('  Failed to download guide data for: %i', int(gridtime))
            else:
                logging.debug('Using cached guide: %s', filename)

            # Parse downloaded or cached file
            if os.path.exists(fileDir):
                try:
                    with gzip.open(fileDir, 'rb') as f:
                        content = f.read()
                        f.close()
                    logging.info('Parsing %s', filename)
                    if count == 0:
                        parseStations(content)
                    TBAcheck = parseEpisodes(content)
                    if TBAcheck == "Unsafe":
                        try:
                            os.remove(fileDir)
                            logging.info('Deleting %s due to TBA listings', filename)
                        except OSError as e:
                            logging.warning('Error Deleting: %s - %s.' % (e.filename, e.strerror))
                except Exception as e:
                    logging.warning('JSON file error for: %s - deleting file', filename)
                    try:
                        os.remove(fileDir)
                    except:
                        pass
            count += 1
            gridtime = gridtime + 10800

        guide_download_time = time.time() - guide_download_start
        stats = downloader.get_stats()
        logging.info('Main guide download completed in %.1fs', guide_download_time)
        logging.info('  Guide requests: %d, WAF blocks: %d', count, stats['waf_blocks'])

        showList = genShowList()
        deleteOldShowCache(showList)
        if xdetails is True:
            logging.info('Extended details enabled - downloading additional program information')
            parseXdetails()
        else:
            logging.info('Extended details disabled - using basic program information only')
        xmltv()
        timeRun = round((time.time() - pythonStartTime),2)
        logging.info('zap2epg completed in %s seconds. ', timeRun)
        logging.info('%s Stations and %s Episodes written to xmltv.xml file.', str(stationCount), str(episodeCount))

        # Final downloader statistics
        final_stats = downloader.get_stats()
        logging.info('Final download statistics:')
        logging.info('  Total requests: %d', final_stats['total_requests'])
        logging.info('  WAF blocks encountered: %d', final_stats['waf_blocks'])
        logging.info('  Final delay: %.2fs', final_stats['current_delay'])

        return timeRun, stationCount, episodeCount
    except Exception as e:
        logging.exception('Exception: main')
    finally:
        # Clean downloader shutdown
        downloader.close()

if __name__ == '__main__':
    userdata = os.getcwd()
    log = os.path.join(userdata, os.environ.get('LogFile'))
    logging.basicConfig(filename=log, filemode='w', format='%(asctime)s %(message)s', datefmt='%Y/%m/%d %H:%M:%S', level=logging.DEBUG)
    result = mainRun(userdata)
    if result is None or result == (None, None, None):
        logging.error('Script failed - exiting with error code')
        sys.exit(1)
    else:
        logging.info('Script completed successfully')
        sys.exit(0)
----EOF

python3 -c "$script"
}

###
### MAIN
###

# Create working directories
[ ! -d $CacheDir ] && mkdir -m 755 -p $CacheDir
[ ! -d $LogDir ] && mkdir -m 755 -p $LogDir
[ ! -d $ConfDir ] && mkdir -m 755 -p $ConfDir

# Clean configuration file if it exists
if [ -f "$ConfFile" ]; then
    clean_config_file "$ConfFile"
fi

# if configuration file doesn't exist
# create one by default (cleaned version)
if [ ! -f "$ConfFile" ]; then
read -r -d '' config <<-"----EOF"
<settings version="3">
  <setting id="zipcode">92101</setting>
  <setting id="lineupcode">lineupId</setting>
  <setting id="lineup">Local Over the Air Broadcast</setting>
  <setting id="device">-</setting>
  <setting id="days">1</setting>
  <setting id="redays">1</setting>
  <setting id="slist"></setting>
  <setting id="stitle">false</setting>
  <setting id="xdetails">true</setting>
  <setting id="xdesc">true</setting>
  <setting id="epgenre">3</setting>
  <setting id="epicon">1</setting>
  <setting id="tvhoff">true</setting>
  <setting id="usern"></setting>
  <setting id="passw"></setting>
  <setting id="tvhurl">127.0.0.1</setting>
  <setting id="tvhport">9981</setting>
  <setting id="tvhmatch">true</setting>
  <setting id="chmatch">true</setting>
</settings>
----EOF
echo "${config}" > "$ConfFile"
fi

# Check output path and ability to write
if [[ ! -d $(dirname $XMLTV) ]]; then
   echo "Output directory for [$(basename $XMLTV)] is inaccessible: $(dirname $XMLTV)"
   exit 1
elif [[ ! -w $(dirname $XMLTV) ]]; then
   echo "Output directory for [$(basename $XMLTV)] is not write accessible: $(dirname $XMLTV)"
   exit 1
fi

# Check that config file exists
if [ ! -f $ConfFile ]; then
   echo "Configuration file missing: $ConfFile"
   exit 1
fi

# Check that offset parameter is either empty or match regex
if [ "$Offset" ] && [[ ! "$Offset" =~ $DaysPattern ]]; then
   echo "Parameter [--offset] unmatched: $Offset"
   exit 1
fi

# Check that days parameter is either empty or match regex
if [ "$Days" ] && [[ ! "$Days" =~ $DaysPattern ]]; then
   echo "Parameter [--days] unmatched: $Days"
   exit 1
fi

# Check that Zip & Postal codes are either empty or match regex
if [ "$ZipCode" ] && [[ ! "$ZipCode" =~ $CACodePattern && ! "$ZipCode" =~ $USCodePattern ]]; then
   echo "Parameter [--zip|--postal|--code] unmatched: $ZipCode"
   exit 1
fi

# Make needed variable accessible to python
export CacheDir
export ConfFile
export LogFile
export XMLTV
[ "$Days" ] && export Days
[ "$Offset" ] && export Offset
[ "$ZipCode" ] && export ZipCode

# Debug: Display environment variables
echo "DEBUG: Environment variables:" >&2
echo "  CacheDir=$CacheDir" >&2
echo "  ConfFile=$ConfFile" >&2
echo "  LogFile=$LogFile" >&2
echo "  ZipCode=$ZipCode" >&2
echo "  Days=$Days" >&2

# Optional: Clear cache to force new download
if [ "$1" = "--clear-cache" ]; then
    echo "Clearing cache directory..." >&2
    rm -f "$CacheDir"/*.json.gz
    rm -f "$CacheDir"/*.json
    shift
fi

# Generate XMLTV file
zap2epg
result=$?
if [ $result = 0 ]; then
  [ ! "$Quiet" == "true" ] && cat $XMLTV
else
  echo "ERROR: zap2epg script failed with exit code $result" >&2
  echo "Check log file: $LogFile" >&2
  exit 1
fi

exit 0
